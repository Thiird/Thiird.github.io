---
date: 2026-01-26
---

<h1 id="ai-thoughts">Thoughts on AI</h1>

Below are a few thoughts about the current AI situation.

Apparently, we live in a bubble that is about to pop.
Not everyone sees it though: while CEOs say AI will replace all software jobs in the coming months, the average person barely knows this is happening at all.

With this kind of confusion going on, I think it's best to take a step back and start with some definitions.

<strong>Artificial intelligence (AI)</strong> is a technological research and application field that aims at developing and deploying computing models whose execution results in anything from a coherent speech to a self-driving car, basically mimicking specific abilities that a human should be capable of.

A big goal of the field is to go beyond the single-task capabilities and reach human-level intelligence, which takes the name of <strong>Artificial General Intelligence (AGI)</strong>.

Some people doubt this "full-consciousness" goal will ever be achieved. The most far-fetched thing I heard was that we need quantum computers to mimic human consciousness.

To me, it all seems very straightforward. Human consciousness is nothing but a very complex computation, performed really fast by the human brain.

We want to replicate <em>what</em> the brain does, not <em>how</em> it does it. For example, many AI models are based on a computational unit called neuron, which is inspired by how the animal brain works. This is akin to how we copied the principle of wings from birds, but not the implementation.

Max Tegmark says this very same thing in his <em>Life 3.0</em> book (from 2017!!):

> "[talking about a brain or an electronic device that performs computation]...information can take on a life of its own, independent of its physical substrate!"
> 
> "...something as intangible as intelligence can be embodied in tangible physical stuff, and we'll soon see how this idea of substrate independence is much deeper, including not only information but also computation and learning."

Will consciousness on a computer ever be achieved? People like Andrej Karpathy and the like are working on the models and people like Jensen Huang and Jim Keller are working on making them run fast. That's all I need to know honestly.

Coming to what is happening in 2026, these developments are very promising and exciting, but people being replaced by AI will be a very big issue. For the moment it's mostly single tasks, but full jobs will follow.

When it comes to software, I'm seeing more and more tasks being taken off my workload by AI. In general, I get to spend less time on the micro things and more on the macro things. On top of that, I can acquire knowledge faster and digest complex topics quicker, as LLMs function as a convenient, though glorified, internet search and personal teacher.

Having to work "less" sounds good on paper, until you realize personal satisfaction and people's livelihoods depend on it. Remove it, and now you have voids to fill: things like the lack of satisfaction and Universal Basic Income start to appear in the public discourse.

I personally have no idea how to fix these issues. George Hotz says that, being a society-level problem, it should be up to the politicians to fix it, and researchers building AI shouldn't concern themselves with it. I can see his point, nonetheless it doesn't make me feel more at ease with the pace of AI progress.

With that being said, it's important to not allow those issues to fog our vision from seeing the power we have in our hands. We should instead focus on seizing all of it for the better of the world.

If you split an atom you can either erase Humanity or make it flourish. It's really up to us to do the right thing.

My ego made me skeptical of AI at first, but then it hit me: why am I complaining about having more capabilities? Imagine a doctor complaining that, thanks to technology, he can now save more patients than ever. Doesn't make sense, does it?

<strong>Bottom line:</strong>

Many technological revolutions have happened in the history of human civilizations, and while perhaps this is the biggest one ever, and possibly the final major one, I don't think we should change our strategy: get on board and join the ride.

It's either that or be left behind.

That's my current approach at least.

---